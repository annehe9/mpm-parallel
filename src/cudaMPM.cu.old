#if __APPLE__
#include <GLUT/glut.h>
#else
//#include <windows.h>
#include <GL/glut.h>
#endif

#include <stdio.h>
#include <iostream>
#include <vector>
#include <cstring>
#include <cmath>
#include <algorithm>
using namespace std;

#include <cuda.h>
#include <cuda_runtime.h>
#include <driver_functions.h>

#include "cudaMPM.h"
#include "helper.h"

// Params we need outside of kernels or that need to be modified
struct GlobalConstants {
	Particle *particles;
	Vector3d *grid_block;
        int *num_p;
        int *grid_x;
        int *grid_y;
        int *block_x;
        int *block_y;
        int *grid_block_x;
        int *grid_block_y;
};

GlobalConstants params;

__constant__ GlobalConstants cuConstParams;

// CPU function
void cudaMPM::addParticles(double xcenter, double ycenter)
{
	for (int i = 0; i < BLOCK_PARTICLES; i++) {
                particles[i + NUM_PARTICLES] = 
                        Particle((((double)rand() / 
                        (double)RAND_MAX) * 2 - 1) * 0.08 + xcenter, 
                        (((double)rand() / (double)RAND_MAX) * 2 - 1) 
                        * 0.08 + ycenter);
	}
	NUM_PARTICLES += BLOCK_PARTICLES;
}

// GPU function
__global__ void P2G(void)
{
        int index = blockIdx.x * blockDim.x + threadIdx.x;
        if (index >= *cuConstParams.num_p) return;
        const Particle& p = cuConstParams.particles[index];
        Vector2i base_coord = (p.x * INV_DX - Vector2d(0.5, 0.5)).cast<int>();
        Vector2d fx = p.x * INV_DX - base_coord.cast<double>();

        // Quadratic kernels [https://www.seas.upenn.edu/~cffjiang/research/mpmcourse/mpmcourse.pdf Eqn. 123, with x=fx, fx-1,fx-2]
        Vector2d onehalf(1.5, 1.5); //have to make these so eigen doesn't give me errors
        Vector2d one(1.0, 1.0);
        Vector2d half(0.5, 0.5);
        Vector2d threequarters(0.75, 0.75);
        Vector2d tmpa = onehalf - fx;
        Vector2d tmpb = fx - one;
        Vector2d tmpc = fx - half;
        Vector2d w[3] = {
          0.5 * (tmpa.cwiseProduct(tmpa)),
          threequarters - (tmpb.cwiseProduct(tmpb)),
          0.5 * (tmpc.cwiseProduct(tmpc))
        };

        // Snow
        // Compute current Lamé parameters [https://www.seas.upenn.edu/~cffjiang/research/mpmcourse/mpmcourse.pdf Eqn. 87]
        double e = exp(HARD * (1.0 - p.Jp));
        double mu = MU_0 * e;
        double lambda = LAMBDA_0 * e;

        // Current volume
        double J = determinant(p.F);

        // Polar decomposition for fixed corotated model, https://www.seas.upenn.edu/~cffjiang/research/mpmcourse/mpmcourse.pdf paragraph after Eqn. 45
        SVDResults *R = (SVDResults *) malloc(sizeof(SVDResults));
        SolveJacobiSVD(p.F, R);
        Matrix2d r = R->U * R->V.transpose();
        Matrix2d s = R->V * R->singularValues * R->V.transpose();

        // [https://www.seas.upenn.edu/~cffjiang/research/mpmcourse/mpmcourse.pdf Paragraph after Eqn. 176]
        double Dinv = 4 * INV_DX * INV_DX;
        // [https://www.seas.upenn.edu/~cffjiang/research/mpmcourse/mpmcourse.pdf Eqn. 52]
        Matrix2d PF_0 = (2 * mu) * (p.F - r) * p.F.transpose();
        double pf1tmp = (lambda * (J - 1) * J);
        Matrix2d PF_1;
        PF_1 << pf1tmp, pf1tmp,
                pf1tmp, pf1tmp;
        Matrix2d PF = PF_0 + PF_1;

        // Cauchy stress times dt and inv_dx
        Matrix2d stress = -(DT * VOL) * (Dinv * PF);

        // Fused APIC momentum + MLS-MPM stress contribution
        // See https://yzhu.io/publication/mpmmls2018siggraph/paper.pdf
        // Eqn 29
        Matrix2d affine = stress + MASS * p.C;

        if (index == 0) {
                printf("P2G: (%d, %d)\n", 
                        base_coord.x() + 1 - *cuConstParams.grid_block_x,
                        base_coord.y() + 1 - *cuConstParams.grid_block_y
                );
        }

        // P2G
        for (int i = 0; i < 3; i++) {
                for (int j = 0; j < 3; j++) {
                        // grid to block
                        int x = base_coord.x() + i - *cuConstParams.grid_block_x;
                        int y = base_coord.y() + j - *cuConstParams.grid_block_y; 
                        Vector2d dpos = (Vector2d(i, j) - fx) * DX;
                        // Translational momentum
                        Vector3d mass_x_velocity(p.v.x() * MASS, p.v.y() * MASS, MASS);
                        Vector2d tmp = affine * dpos;
                        *(Vector3d*)(&cuConstParams.grid_block)[x * *cuConstParams.grid_y + y] += (
                                w[i].x() * w[j].y() * (mass_x_velocity + Vector3d(tmp.x(), tmp.y(), 0))
                        );
                }
        }
}

// GPU function
__global__ void UpdateGridVelocity(void) {
        int index = blockIdx.x * blockDim.x + threadIdx.x;
        if (index >= *cuConstParams.grid_x * *cuConstParams.grid_y) return;
        Vector3d& g = cuConstParams.grid_block[index];
        // block to grid
        int i = index / *cuConstParams.grid_y + *cuConstParams.grid_block_x;
        int j = index % *cuConstParams.grid_y + *cuConstParams.grid_block_y;
        if (index == 0) {
                printf("Vel: (%d, %d)\n", i, j);
        }
        if (g[2] > 0) {
                // Normalize by mass
                g /= g[2];
                // Gravity
                g += DT * Vector3d(0, -200, 0);

                // boundary thickness
                double boundary = 0.05;
                // Node coordinates
                double x = (double)i / GRID_RES;
                double y = (double)j / GRID_RES;

                // Sticky boundary
                if (x < boundary || x > 1 - boundary) {
                        g[0] = 0.0;
                }
                // Separate boundary
                if (y < boundary || y > 1 - boundary) {
                        g[1] = 0.0;
                }
        }
}

// GPU function
__global__ void G2P(void)
{
        int index = blockIdx.x * blockDim.x + threadIdx.x;
        if (index >= *cuConstParams.num_p) return;
        Particle& p = cuConstParams.particles[index];
        // element-wise floor
        Vector2i base_coord = (p.x * INV_DX - Vector2d(0.5, 0.5)).cast<int>();
        Vector2d fx = p.x * INV_DX - base_coord.cast<double>();

        // Quadratic kernels [https://www.seas.upenn.edu/~cffjiang/research/mpmcourse/mpmcourse.pdf Eqn. 123, with x=fx, fx-1,fx-2]
        Vector2d onehalf(1.5, 1.5); //have to make these so eigen doesn't give me errors
        Vector2d one(1.0, 1.0);
        Vector2d half(0.5, 0.5);
        Vector2d threequarters(0.75, 0.75);
        Vector2d tmpa = onehalf - fx;
        Vector2d tmpb = fx - one;
        Vector2d tmpc = fx - half;
        Vector2d w[3] = {
          0.5 * (tmpa.cwiseProduct(tmpa)),
          threequarters - (tmpb.cwiseProduct(tmpb)),
          0.5 * (tmpc.cwiseProduct(tmpc))
        };

        p.C = Matrix2d::Zero();
        p.v = Vector2d::Zero();

        // constructing affine per-particle momentum matrix from APIC / MLS-MPM.
        // see APIC paper (https://www.math.ucla.edu/~jteran/papers/JSSTS15.pdf), page 6
        // below equation 11 for clarification. this is calculating C = B * (D^-1) for APIC equation 8,
        // where B is calculated in the inner loop at (D^-1) = 4 is a constant when using quadratic interpolation functions
        if (index == 0) {
                printf("G2P: (%d, %d)\n", 
                        base_coord.x() + 1 - *cuConstParams.grid_block_x,
                        base_coord.y() + 1 - *cuConstParams.grid_block_y
                );
        }

        for (int i = 0; i < 3; i++) {
                for (int j = 0; j < 3; j++) {
                        // grid to block
                        int x = base_coord.x() + i - *cuConstParams.grid_block_x;
                        int y = base_coord.y() + j - *cuConstParams.grid_block_y; 
                        Vector2d dpos = (Vector2d(i, j) - fx);
                        Vector3d curr = cuConstParams.grid_block[x * *cuConstParams.grid_y + y];
                        Vector2d grid_v(curr.x(), curr.y());
                        double weight = w[i].x() * w[j].y();
                        // Velocity
                        p.v += weight * grid_v;
                        // APIC C, outer product of weighted velocity and dist, paper equation 10
                        p.C += 4 * INV_DX * ((weight * grid_v) * dpos.transpose());
                }
        }

        // Advection
        // UPDATE PARTICLE POSITION 
        //double tempy = p.x.y();
        p.x += DT * p.v;

        // MLS-MPM F-update eqn 17
        Matrix2d F = (Matrix2d::Identity() + DT * p.C) * p.F;

        SVDResults *R = (SVDResults *) malloc(sizeof(SVDResults));
        SolveJacobiSVD(F, R);
        Matrix2d svd_u = R->U;
        Matrix2d svd_v = R->V;
        // Snow Plasticity
        Matrix2d sig = R->singularValues;
        sig(0, 0) = min(max(sig(0, 0), 1.0 - 2.5e-2), 1.0 + 7.5e-3);
        sig(1, 1) = min(max(sig(1, 1), 1.0 - 2.5e-2), 1.0 + 7.5e-3);

        double oldJ = determinant(F);
        F = svd_u * sig * svd_v.transpose();

        double Jp_new = min(max(p.Jp * oldJ / determinant(F), 0.6), 20.0);

        p.Jp = Jp_new;
        p.F = F;
}

__global__ void dummy(void)
{
        int index = blockIdx.x * blockDim.x + threadIdx.x;
        Particle *particles = cuConstParams.particles;
        printf("dummy: %d %p\n", index, (void *)particles);
        //Particle& p = cuConstParams.particles[index];
        particles[index].x(0) = 1.0;
        particles[index].x(1) = 1.0;
        particles[index].Jp = 0.0;
}


// CPU
void cudaMPM::Update(void)
{
        // parallelization over particles
        dim3 blockDim(BLOCKSIZE, 1);
        dim3 gridDim(1, 1);
        // parallelization over grid
	dim3 blockDimG(BLOCKSIZE, 1);//BLOCKSIDE, BLOCKSIDE);
        dim3 gridDimG(1, 1);

        /*
        // copy particle data to GPU
        cudaMemcpy(
                (void*)cudaDeviceParticles,
                (void*)particles,
                sizeof(Particle) * NUM_PARTICLES, 
                cudaMemcpyHostToDevice
        );
        printf("particles: %p cuda: %p\n", (void *)particles, (void *) cudaDeviceParticles);

        for (int a = 0; a < NUM_PARTICLES; a++) {
                printf("particles before: (%f, %f) %f\n", particles[a].x(0), particles[a].x(1), particles[a].Jp);
        }

        dummy<<<gridDim, blockDim>>>();
        cudaDeviceSynchronize();

        // copy particle data back to CPU
        cudaMemcpy(
                (void*)particles,
                (void*)cudaDeviceParticles,
                sizeof(Particle) * NUM_PARTICLES, 
                cudaMemcpyDeviceToHost
        );
        for (int a = 0; a < NUM_PARTICLES; a++) {
                printf("particles after: (%f, %f) %f\n", particles[a].x(0), particles[a].x(1), particles[a].Jp);
        }
        */

        int index, p_block_size, p_iterations, p_counter, i, j, k, m, n;

        // starting point of block (wrap around for neighbors)
        int nsize = 0;

        if (DEBUG) cout << "initialized vars" << endl;

        // clear CPU grid
        memset(grid, 0, NUM_CELLS);

        if (DEBUG) cout << "clear CPU grid" << endl;
        if (DEBUG) cout << "NUM_PARTICLES: " << NUM_PARTICLES << endl;
        if (DEBUG) cout << "GRID_RES: " << GRID_RES << endl;
        if (DEBUG) cout << "TRUE_GRID_RES: " << TRUE_GRID_RES << endl;
        if (DEBUG) cout << "BLOCKSIDE: " << BLOCKSIDE << endl;
        if (DEBUG) cout << "GRID_BLOCK_SIDE: " << GRID_BLOCK_SIDE << endl;
        if (DEBUG) cout << "\n" << endl;


        // process grids and particles in blocks
        *xBlockinGrid = 0;
        for (i = 0; i < GRID_BLOCK_SIDE; i++) {
                *yBlockinGrid = 0;
                for (j = 0; j < GRID_BLOCK_SIDE; j++) {

                        index = i * GRID_BLOCK_SIDE + j;
                        *xBlock = i;
                        *yBlock = j;

                        if (DEBUG) printf("Block (%d, %d) => %d\n", *xBlock, *yBlock, index);
                        if (DEBUG) printf("Block grid indices: (%d, %d)\n", *xBlockinGrid, *yBlockinGrid);

                        p_block_size = retrieve_block(index, particles, particle_set);
                        if (DEBUG) cout << "p_block_size: " << p_block_size << endl;

                        if (*xBlockinGrid + BLOCKSIDE >= GRID_RES) {
                                *xSize = GRID_RES - *xBlockinGrid;
                        }
                        else {
                                *xSize = BLOCKSIDE;
                        }
                        if (*yBlockinGrid + BLOCKSIDE >= GRID_RES) {
                                *ySize = GRID_RES - *yBlockinGrid;
                        }
                        else {
                                *ySize = BLOCKSIDE;
                        }
                        if (DEBUG) printf("Block size (%d, %d)\n", *xSize, *ySize);

                        if (p_block_size > 0) {
                                // copy grid block to grid_block
                                for (m = 0; m < *xSize; m++) {
                                        for (n = 0; n < *ySize; n++) {
                                                grid_block[m * *ySize + n] =
                                                        grid[(m + *xBlockinGrid) * *ySize + (n + *yBlockinGrid)];
                                        }
                                }
                                if (DEBUG) cout << "copy grid to block: " << endl;

                                // copy grid data to GPU to get neighbors
                                cudaMemcpy(
                                        (void *)cudaDeviceBlock, 
                                        (void *)grid_block,
                                        sizeof(Vector3d) * *xSize * *ySize, 
                                        cudaMemcpyHostToDevice
                                );
                                if (DEBUG) cout << "copy block to GPU" << endl;

                                p_iterations = (p_block_size + BLOCKSIZE - 1) / BLOCKSIZE;

                                if (DEBUG) cout << "p_iterations: " << p_iterations << endl;

                                if (DEBUG) printf("particle_set\nx: (%f, %f)\nv: (%f, %f)\n", 
                                        particle_set[0].x(0), particle_set[0].x(1),
                                        particle_set[0].v(0), particle_set[0].v(1)
                                );
                                
                                p_counter = 0;
                                for (k = 0; k < p_iterations; k++) {
                                        if (DEBUG) cout << "particle iteration: " << k << endl;

                                        if (k == p_iterations - 1) {
                                                *pSize = p_block_size - p_counter;
                                        }
                                        else {
                                                *pSize = BLOCKSIZE;
                                        }
                                        if (DEBUG) cout << "pSize: " << *pSize << endl;

                                        // copy particle data to GPU
                                        cudaMemcpy(
                                                (void*)cudaDeviceParticles,
                                                (void*)(particle_set + p_counter),
                                                sizeof(Particle) * *pSize, 
                                                cudaMemcpyHostToDevice
                                        );

                                        if (DEBUG) cout << "particle data to GPU @ " << p_counter << endl;

                                        // TODO may be better to run all of these
                                        // in own Update with sync_threads?
                                        P2G<<<gridDim, blockDim>>>();
                                        if (DEBUG) cout << "P2G" << endl;
                                        UpdateGridVelocity<<<gridDimG, blockDimG>>>();
                                        if (DEBUG) cout << "UpdateGridVelocity" << endl;
                                        G2P<<<gridDim, blockDim>>>();
                                        if (DEBUG) cout << "G2P" << endl;
                                        cudaDeviceSynchronize();

                                        // copy particle data back to CPU
                                        cudaMemcpy(
                                                (void*)(particle_next + nsize),
                                                (void*)cudaDeviceParticles,
                                                sizeof(Particle) * *pSize, 
                                                cudaMemcpyDeviceToHost
                                        );

                                        if (DEBUG) cout << "particle data to CPU @ " << nsize << endl;

                                        p_counter += *pSize;
                                        nsize += *pSize;
                                }
                                if (DEBUG) cout << "done with particle iterations" << endl;

                                if (DEBUG) printf("particle_next\nx: (%f, %f)\nv: (%f, %f)\n", 
                                        particle_next[nsize - p_block_size].x(0), particle_next[nsize - p_block_size].x(1),
                                        particle_next[nsize - p_block_size].v(0), particle_next[nsize - p_block_size].v(1)
                                );

                                // copy grid data back to CPU
                                cudaMemcpy(
                                        (void *)grid_block,
                                        (void *)cudaDeviceBlock, 
                                        sizeof(Vector3d) * *xSize * *ySize, 
                                        cudaMemcpyDeviceToHost
                                );
                                if (DEBUG) cout << "Copy block to CPU" << endl;

                                // copy grid_block to grid block
                                for (m = 0; m < *xSize; m++) {
                                        for (n = 0; n < *ySize; n++) {
                                                grid[(m + *xBlockinGrid) * *ySize + (n + *yBlockinGrid)]
                                                        = grid_block[m * *ySize + n];
                                        }
                                }
                                if (DEBUG) cout << "Copy block to grid" << endl;
                        }
                        if (DEBUG) cout << "\n";
                        // starting point of block (wrap around for neighbors)
                        *yBlockinGrid += OFFSIDE;
                }
                // starting point of block (wrap around for neighbors)
                *xBlockinGrid += OFFSIDE;
        }

        // swap particle buffers by changing pointers
        // variable should contain address to first element
        if (DEBUG) cout << "before swap: " << particles << " " << particle_next << endl;
        Particle *temp = particles;
        particles = particle_next;
        particle_next = temp;
        if (DEBUG) cout << "after swap: " << particles << " " << particle_next << endl;

        // Update blocks each particle is in.
        map_particles(particles, NUM_PARTICLES);
        if (DEBUG) cout << "map particles again" << endl;

        if (DEBUG) cout << "\n\n";
}

// CPU
cudaMPM::cudaMPM() {
	NUM_PARTICLES = 0;

        particles = (Particle *) malloc(sizeof(Particle) * MAX_PARTICLES);
        pSize = (int *) malloc(sizeof(int));

        grid = (Vector3d *) malloc(sizeof(Vector3d) * NUM_CELLS);
        grid_block = (Vector3d *) malloc(sizeof(Vector3d) * BLOCKSIZE);
        xSize = (int *) malloc(sizeof(int));
        ySize = (int *) malloc(sizeof(int));
        xBlock = (int *) malloc(sizeof(int));
        yBlock = (int *) malloc(sizeof(int));
        xBlockinGrid = (int *) malloc(sizeof(int));
        yBlockinGrid = (int *) malloc(sizeof(int));
}

// CPU, prep GPU
void cudaMPM::setup(void)
{
        // CPU particles
	addParticles(0.55, 0.45);
	addParticles(0.45, 0.65);
	addParticles(0.55, 0.85);

	cout << "initializing mpm with " << NUM_PARTICLES / 3 << " particles" << endl;

        particle_set = (Particle *) malloc(sizeof(Particle) * NUM_PARTICLES);
        particle_next = (Particle *) malloc(sizeof(Particle) * NUM_PARTICLES);

        // GPU memory
	cudaMalloc(
                (void**)&cudaDeviceParticles, 
                sizeof(Particle) * BLOCKSIZE
        );

        // outer ring is for neighborhood 
	cudaMalloc(
                (void**)&cudaDeviceBlock, 
                sizeof(Vector3d) * BLOCKSIZE
        );

        // get global cuda params
        params.num_p = pSize;
        params.grid_x = xSize;
        params.grid_y = ySize;
        params.grid_block_x = xBlockinGrid;
        params.grid_block_y = yBlockinGrid;
        params.block_x = xBlock;
        params.block_y = yBlock;
	params.particles = cudaDeviceParticles;
	params.grid_block = cudaDeviceBlock;

        cudaMemcpyToSymbol(
                cuConstParams,
                &params,
                sizeof(GlobalConstants)
        );

        // begin data structure
        map_particles(particles, NUM_PARTICLES);
}
